# Instructions

During your interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a Scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the Scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the Scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Tools

Note all the tools are in python3. So in the case you need to do batch processing, you can always consult the python files and write your own script.

## Screenshot Verification

The screenshot verification workflow allows you to capture screenshots of web pages and verify their appearance using LLMs. The following tools are available:

1. Screenshot Capture:
```bash
venv/bin/python3 tools/screenshot_utils.py URL [--output OUTPUT] [--width WIDTH] [--height HEIGHT]
```

2. LLM Verification with Images:
```bash
venv/bin/python3 tools/llm_api.py --prompt "Your verification question" --provider {openai|anthropic} --image path/to/screenshot.png
```

Example workflow:
```python
from screenshot_utils import take_screenshot_sync
from llm_api import query_llm

# Take a screenshot

screenshot_path = take_screenshot_sync('https://example.com', 'screenshot.png')

# Verify with LLM

response = query_llm(
    "What is the background color and title of this webpage?",
    provider="openai",  # or "anthropic"
    image_path=screenshot_path
)
print(response)
```

## LLM

You always have an LLM at your side to help you with the task. For simple tasks, you could invoke the LLM by running the following command:
```
venv/bin/python3 ./tools/llm_api.py --prompt "What is the capital of France?" --provider "anthropic"
```

The LLM API supports multiple providers:
- OpenAI (default, model: gpt-4o)
- Azure OpenAI (model: configured via AZURE_OPENAI_MODEL_DEPLOYMENT in .env file, defaults to gpt-4o-ms)
- DeepSeek (model: deepseek-chat)
- Anthropic (model: claude-3-sonnet-20240229)
- Gemini (model: gemini-pro)
- Local LLM (model: Qwen/Qwen2.5-32B-Instruct-AWQ)

But usually it's a better idea to check the content of the file and use the APIs in the `tools/llm_api.py` file to invoke the LLM if needed.

## Web browser

You could use the `tools/web_scraper.py` file to scrape the web.
```bash
venv/bin/python3 ./tools/web_scraper.py --max-concurrent 3 URL1 URL2 URL3
```
This will output the content of the web pages.

## Search engine

You could use the `tools/search_engine.py` file to search the web.
```bash
venv/bin/python3 ./tools/search_engine.py "your search keywords"
```
This will output the search results in the following format:
```
URL: https://example.com
Title: This is the title of the search result
Snippet: This is a snippet of the search result
```
If needed, you can further use the `web_scraper.py` file to scrape the web page content.

# Lessons

## User Specified Lessons

- You have a python venv in ./venv. Always use (activate) it when doing python development. First, to check whether 'uv' is available, use `which uv`. If that's the case, first activate the venv, and then use `uv pip install` to install packages. Otherwise, fall back to `pip`.
- Due to Cursor's limit, when you use `git` and `gh` and need to submit a multiline commit message, first write the message in a file, and then use `git commit -F <filename>` or similar command to commit. And then remove the file. Include "[Cursor] " in the commit message and PR title.

## Cursor learned

- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes
- Use 'gpt-4o' as the model name for OpenAI's GPT-4 with vision capabilities
- When searching for recent news, use the current year (2025) instead of previous years, or simply use the "recent" keyword to get the latest information

# Scratchpad

## 当前任务：Dify工作流配置研究

### 任务概述：
- 目标：研究、解读和优化Dify的工作流配置
- 范围：DSL格式（.yml）文件的分析和优化
- 分支：基于master创建新的研究分支
- 文件规模：2800+行，需要采用分治策略
- 工作流结构：6个主要节点的线性流程
  1. 开始节点
  2. 入参解析
  3. sentence上下文关联处理
  4. 调用模型
  5. HTTP终态回传
  6. 结束节点

### 分析思路：
采用程序员调试代码的方式进行分析：

1. 数据流分析
   - 追踪数据在节点间的传递
   - 识别关键数据结构和转换
   - 记录数据的生命周期

2. 控制流分析
   - 理解节点间的调用关系
   - 识别条件分支和循环
   - 分析错误处理机制

3. 节点功能分析
   - 每个节点的具体职责
   - 输入输出规范
   - 内部处理逻辑

4. 调试式理解
   - 从入口节点开始逐步分析
   - 关注数据转换和状态变化
   - 记录关键检查点

### 任务步骤：
[X] 1. 分支准备
    - 从master创建新的研究分支 ✓
    - 设置分支命名规范 ✓
    - 更新分支说明 ✓

[X] 2. 工作空间准备
    - 创建专门的研究目录结构 ✓
    - 准备文档模板 ✓
    - 设置必要的工具和依赖 ✓

[ ] 3. DSL文件分析（分治策略）
    - 工作流结构分析
        - 绘制节点依赖关系图
        - 标注数据流向
        - 识别关键检查点
    - 节点模块分析
        - 入参解析节点
        - 上下文处理节点
        - 模型调用节点
        - HTTP回传节点
    - 数据流分析
        - 输入数据结构
        - 中间态数据
        - 输出数据结构
    - 控制流分析
        - 条件判断逻辑
        - 错误处理机制
        - 状态管理方式

[ ] 4. 工作流复刻（分治策略）
    - 模块化实现
        - 数据结构定义
        - 节点功能实现
        - 流程控制逻辑
    - 集成测试
        - 节点单元测试
        - 数据流测试
        - 端到端测试

[ ] 5. 优化改进（分治策略）
    - 节点级优化
        - 数据处理效率
        - 错误处理完善
        - 接口规范化
    - 流程级优化
        - 并行处理机会
        - 资源利用优化
        - 可维护性提升

[ ] 6. 文档完善
    - 节点文档
        - 功能说明
        - 接口规范
        - 示例说明
    - 系统文档
        - 架构说明
        - 数据流图
        - 部署指南

### 进度追踪：
- 开始时间：[当前]
- 状态：DSL文件分析阶段
- 当前步骤：工作流结构分析
- 下一步：绘制节点依赖关系图

### 注意事项：
- 保持代码和文档的同步更新
- 记录所有重要的发现和决策
- 确保优化方案的可维护性
- 采用分治策略处理大型配置文件
- 每个节点的分析都要有清晰的文档
- 注意节点间的数据流和依赖关系
- 使用调试思维理解工作流逻辑
